{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36662, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('reddit_preprocessing.csv').dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 23:43:38,777] A new study created in memory with name: no-name-a9431626-1d40-4bd4-87f0-498fbe5b8174\n",
      "[I 2025-02-10 23:43:38,940] Trial 0 finished with value: 0.4301544554731719 and parameters: {'C': 0.006401481341040295, 'penalty': 'l1'}. Best is trial 0 with value: 0.4301544554731719.\n",
      "[I 2025-02-10 23:43:39,175] Trial 1 finished with value: 0.6947045947153376 and parameters: {'C': 0.06098699434978811, 'penalty': 'l1'}. Best is trial 1 with value: 0.6947045947153376.\n",
      "[I 2025-02-10 23:43:39,355] Trial 2 finished with value: 0.6762929116857908 and parameters: {'C': 0.0031574399936313753, 'penalty': 'l2'}. Best is trial 1 with value: 0.6947045947153376.\n",
      "[I 2025-02-10 23:43:39,485] Trial 3 finished with value: 0.6673257336555043 and parameters: {'C': 0.0010035266167671242, 'penalty': 'l2'}. Best is trial 1 with value: 0.6947045947153376.\n",
      "[I 2025-02-10 23:43:39,625] Trial 4 finished with value: 0.4301544554731719 and parameters: {'C': 0.005810024987815241, 'penalty': 'l1'}. Best is trial 1 with value: 0.6947045947153376.\n",
      "[I 2025-02-10 23:43:39,735] Trial 5 finished with value: 0.22496504921362548 and parameters: {'C': 0.0001452331253675627, 'penalty': 'l1'}. Best is trial 1 with value: 0.6947045947153376.\n",
      "[I 2025-02-10 23:43:41,092] Trial 6 finished with value: 0.7814106985535731 and parameters: {'C': 9.294087242716621, 'penalty': 'l2'}. Best is trial 6 with value: 0.7814106985535731.\n",
      "[I 2025-02-10 23:43:41,245] Trial 7 finished with value: 0.4301544554731719 and parameters: {'C': 0.004495358958077197, 'penalty': 'l1'}. Best is trial 6 with value: 0.7814106985535731.\n",
      "[I 2025-02-10 23:43:41,775] Trial 8 finished with value: 0.8023455815863754 and parameters: {'C': 1.881507175324831, 'penalty': 'l1'}. Best is trial 8 with value: 0.8023455815863754.\n",
      "[I 2025-02-10 23:43:42,555] Trial 9 finished with value: 0.7840019602320538 and parameters: {'C': 1.134957644288192, 'penalty': 'l2'}. Best is trial 8 with value: 0.8023455815863754.\n",
      "[I 2025-02-10 23:43:42,908] Trial 10 finished with value: 0.7801832863476406 and parameters: {'C': 0.2121082675558696, 'penalty': 'l1'}. Best is trial 8 with value: 0.8023455815863754.\n",
      "[I 2025-02-10 23:43:44,025] Trial 11 finished with value: 0.7837633083740916 and parameters: {'C': 2.5832396707741823, 'penalty': 'l2'}. Best is trial 8 with value: 0.8023455815863754.\n",
      "[I 2025-02-10 23:43:44,996] Trial 12 finished with value: 0.783320041309042 and parameters: {'C': 0.850393398208484, 'penalty': 'l2'}. Best is trial 8 with value: 0.8023455815863754.\n",
      "[I 2025-02-10 23:43:45,857] Trial 13 finished with value: 0.7814788764940447 and parameters: {'C': 0.526751649857056, 'penalty': 'l2'}. Best is trial 8 with value: 0.8023455815863754.\n",
      "[I 2025-02-10 23:43:46,454] Trial 14 finished with value: 0.7973333751888221 and parameters: {'C': 6.413854179295593, 'penalty': 'l1'}. Best is trial 8 with value: 0.8023455815863754.\n",
      "[I 2025-02-10 23:43:47,029] Trial 15 finished with value: 0.7971628838315444 and parameters: {'C': 6.882765936049894, 'penalty': 'l1'}. Best is trial 8 with value: 0.8023455815863754.\n",
      "[I 2025-02-10 23:43:47,319] Trial 16 finished with value: 0.7620101040312358 and parameters: {'C': 0.1360515678880077, 'penalty': 'l1'}. Best is trial 8 with value: 0.8023455815863754.\n",
      "[I 2025-02-10 23:43:47,855] Trial 17 finished with value: 0.8001634049905114 and parameters: {'C': 2.7387435620684717, 'penalty': 'l1'}. Best is trial 8 with value: 0.8023455815863754.\n",
      "[I 2025-02-10 23:43:48,095] Trial 18 finished with value: 0.6389579320365689 and parameters: {'C': 0.033605756051680064, 'penalty': 'l1'}. Best is trial 8 with value: 0.8023455815863754.\n",
      "[I 2025-02-10 23:43:48,632] Trial 19 finished with value: 0.8022773920193791 and parameters: {'C': 1.916392948020222, 'penalty': 'l1'}. Best is trial 8 with value: 0.8023455815863754.\n",
      "[I 2025-02-10 23:43:49,149] Trial 20 finished with value: 0.7900369461886653 and parameters: {'C': 0.2922378448459648, 'penalty': 'l1'}. Best is trial 8 with value: 0.8023455815863754.\n",
      "[I 2025-02-10 23:43:49,980] Trial 21 finished with value: 0.8022432972358808 and parameters: {'C': 1.868322251644101, 'penalty': 'l1'}. Best is trial 8 with value: 0.8023455815863754.\n",
      "[I 2025-02-10 23:43:50,858] Trial 22 finished with value: 0.8013908985821162 and parameters: {'C': 2.1742683340441458, 'penalty': 'l1'}. Best is trial 8 with value: 0.8023455815863754.\n",
      "[I 2025-02-10 23:43:51,280] Trial 23 finished with value: 0.7331988958289551 and parameters: {'C': 0.09324563804636257, 'penalty': 'l1'}. Best is trial 8 with value: 0.8023455815863754.\n",
      "[I 2025-02-10 23:43:51,927] Trial 24 finished with value: 0.8001975637198949 and parameters: {'C': 0.5052717835320064, 'penalty': 'l1'}. Best is trial 8 with value: 0.8023455815863754.\n",
      "[I 2025-02-10 23:43:52,725] Trial 25 finished with value: 0.8024478717501321 and parameters: {'C': 1.7668688310340903, 'penalty': 'l1'}. Best is trial 25 with value: 0.8024478717501321.\n",
      "[I 2025-02-10 23:43:53,628] Trial 26 finished with value: 0.7990381783096139 and parameters: {'C': 3.6549415783947214, 'penalty': 'l1'}. Best is trial 25 with value: 0.8024478717501321.\n",
      "[I 2025-02-10 23:43:54,397] Trial 27 finished with value: 0.8025160671303905 and parameters: {'C': 0.8987369533664632, 'penalty': 'l1'}. Best is trial 27 with value: 0.8025160671303905.\n",
      "[I 2025-02-10 23:43:54,987] Trial 28 finished with value: 0.7984927722256279 and parameters: {'C': 0.44265024943768433, 'penalty': 'l1'}. Best is trial 27 with value: 0.8025160671303905.\n",
      "[I 2025-02-10 23:43:55,249] Trial 29 finished with value: 0.5853590895733618 and parameters: {'C': 0.01891686889541592, 'penalty': 'l1'}. Best is trial 27 with value: 0.8025160671303905.\n",
      "[I 2025-02-10 23:43:55,961] Trial 30 finished with value: 0.8025842450708621 and parameters: {'C': 0.8289241511809371, 'penalty': 'l1'}. Best is trial 30 with value: 0.8025842450708621.\n",
      "[I 2025-02-10 23:43:56,719] Trial 31 finished with value: 0.8028229085553491 and parameters: {'C': 1.009060816555515, 'penalty': 'l1'}. Best is trial 31 with value: 0.8028229085553491.\n",
      "[I 2025-02-10 23:43:57,503] Trial 32 finished with value: 0.8025160671303905 and parameters: {'C': 0.8892926566964823, 'penalty': 'l1'}. Best is trial 31 with value: 0.8028229085553491.\n",
      "[I 2025-02-10 23:43:57,892] Trial 33 finished with value: 0.68999939832735 and parameters: {'C': 0.05816117340701471, 'penalty': 'l1'}. Best is trial 31 with value: 0.8028229085553491.\n",
      "[I 2025-02-10 23:43:58,659] Trial 34 finished with value: 0.8024478426838204 and parameters: {'C': 0.7943229996927137, 'penalty': 'l1'}. Best is trial 31 with value: 0.8028229085553491.\n",
      "[I 2025-02-10 23:43:59,112] Trial 35 finished with value: 0.7807970447699677 and parameters: {'C': 0.21539784043839985, 'penalty': 'l1'}. Best is trial 31 with value: 0.8028229085553491.\n",
      "[I 2025-02-10 23:43:59,364] Trial 36 finished with value: 0.4584539977659633 and parameters: {'C': 0.0139922477875719, 'penalty': 'l1'}. Best is trial 31 with value: 0.8028229085553491.\n",
      "[I 2025-02-10 23:43:59,572] Trial 37 finished with value: 0.4301544554731719 and parameters: {'C': 0.0009720746483131989, 'penalty': 'l1'}. Best is trial 31 with value: 0.8028229085553491.\n",
      "[I 2025-02-10 23:44:00,360] Trial 38 finished with value: 0.7576797874903828 and parameters: {'C': 0.10574392887065388, 'penalty': 'l2'}. Best is trial 31 with value: 0.8028229085553491.\n",
      "[I 2025-02-10 23:44:01,299] Trial 39 finished with value: 0.7980494121483812 and parameters: {'C': 4.459109407715323, 'penalty': 'l1'}. Best is trial 31 with value: 0.8028229085553491.\n",
      "[I 2025-02-10 23:44:02,085] Trial 40 finished with value: 0.8028911213753946 and parameters: {'C': 1.0415352084601333, 'penalty': 'l1'}. Best is trial 40 with value: 0.8028911213753946.\n",
      "[I 2025-02-10 23:44:02,803] Trial 41 finished with value: 0.802686517794832 and parameters: {'C': 0.719891802871338, 'penalty': 'l1'}. Best is trial 40 with value: 0.8028911213753946.\n",
      "[I 2025-02-10 23:44:03,390] Trial 42 finished with value: 0.7936170147212148 and parameters: {'C': 0.3400558424426621, 'penalty': 'l1'}. Best is trial 40 with value: 0.8028911213753946.\n",
      "[I 2025-02-10 23:44:04,119] Trial 43 finished with value: 0.8024819723468927 and parameters: {'C': 0.8929798264000369, 'penalty': 'l1'}. Best is trial 40 with value: 0.8028911213753946.\n",
      "[I 2025-02-10 23:44:04,783] Trial 44 finished with value: 0.8009817669934012 and parameters: {'C': 0.538053842343583, 'penalty': 'l1'}. Best is trial 40 with value: 0.8028911213753946.\n",
      "[I 2025-02-10 23:44:06,274] Trial 45 finished with value: 0.7833200296825173 and parameters: {'C': 1.2646146345469413, 'penalty': 'l2'}. Best is trial 40 with value: 0.8028911213753946.\n",
      "[I 2025-02-10 23:44:07,393] Trial 46 finished with value: 0.796003620499772 and parameters: {'C': 9.889830985225032, 'penalty': 'l1'}. Best is trial 40 with value: 0.8028911213753946.\n",
      "[I 2025-02-10 23:44:07,575] Trial 47 finished with value: 0.22496504921362548 and parameters: {'C': 0.0001370680387718673, 'penalty': 'l1'}. Best is trial 40 with value: 0.8028911213753946.\n",
      "[I 2025-02-10 23:44:08,921] Trial 48 finished with value: 0.7701588386729601 and parameters: {'C': 0.1969600640065818, 'penalty': 'l2'}. Best is trial 40 with value: 0.8028911213753946.\n",
      "[I 2025-02-10 23:44:09,959] Trial 49 finished with value: 0.7977766248140845 and parameters: {'C': 5.091305434511325, 'penalty': 'l1'}. Best is trial 40 with value: 0.8028911213753946.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 1.0415352084601333, 'penalty': 'l1'}\n",
      "Test Accuracy: 0.7984\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Remove rows where the target labels (category) are NaN\n",
    "df = df.dropna(subset=['category'])\n",
    "\n",
    "# Step 2: TF-IDF vectorization setup\n",
    "ngram_range = (1, 3)  # Trigram\n",
    "max_features = 1000  # Set max_features to 1000\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "\n",
    "# **Step 3: Train-test split**\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category']\n",
    ")\n",
    "\n",
    "# **Step 4: Fit TF-IDF only on training data**\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# **Step 5: Compute Class Weights Instead of SMOTE**\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=np.unique(y_train), y=y_train)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(np.unique(y_train), class_weights)}\n",
    "\n",
    "# Step 6: Optuna objective function with Stratified K-Fold CV\n",
    "def objective_logreg(trial):\n",
    "    C = trial.suggest_float('C', 1e-4, 10.0, log=True)\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "    solver = 'liblinear' if penalty == 'l1' else 'lbfgs'\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        C=C, penalty=penalty, solver=solver, class_weight=class_weight_dict, random_state=42\n",
    "    )\n",
    "\n",
    "    # Perform Stratified K-Fold Cross-Validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train_vec, y_train, cv=skf, scoring='accuracy')\n",
    "\n",
    "    return scores.mean()  # Return mean accuracy across folds\n",
    "\n",
    "# Step 7: Run Optuna with early stopping\n",
    "def run_optuna_experiment():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective_logreg, n_trials=50, timeout=600)  # 50 trials or 10 min max\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = study.best_params\n",
    "    best_model = LogisticRegression(\n",
    "        C=best_params['C'], penalty=best_params['penalty'], \n",
    "        solver='liblinear' if best_params['penalty'] == 'l1' else 'lbfgs',\n",
    "        class_weight=class_weight_dict, random_state=42\n",
    "    )\n",
    "\n",
    "    # Train final model on full training data\n",
    "    best_model.fit(X_train_vec, y_train)\n",
    "\n",
    "    # Evaluate on test data\n",
    "    y_pred = best_model.predict(X_test_vec)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Run the experiment\n",
    "run_optuna_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-10 23:45:50,838] A new study created in memory with name: no-name-38863503-39fa-4f5b-9bb6-d213e8f4bd65\n",
      "[I 2025-02-10 23:45:53,463] Trial 0 finished with value: 0.878925174303404 and parameters: {'C': 2.2943012059790817, 'penalty': 'l1'}. Best is trial 0 with value: 0.878925174303404.\n",
      "[I 2025-02-10 23:45:55,086] Trial 1 finished with value: 0.6919089212939509 and parameters: {'C': 0.007244749055966219, 'penalty': 'l2'}. Best is trial 0 with value: 0.878925174303404.\n",
      "[I 2025-02-10 23:45:56,851] Trial 2 finished with value: 0.7914689561618983 and parameters: {'C': 0.2696153201010838, 'penalty': 'l1'}. Best is trial 0 with value: 0.878925174303404.\n",
      "[I 2025-02-10 23:45:57,111] Trial 3 finished with value: 0.4301544554731719 and parameters: {'C': 0.0014493741104949058, 'penalty': 'l1'}. Best is trial 0 with value: 0.878925174303404.\n",
      "[I 2025-02-10 23:45:58,157] Trial 4 finished with value: 0.840328571399505 and parameters: {'C': 2.7943140231269403, 'penalty': 'l2'}. Best is trial 0 with value: 0.878925174303404.\n",
      "[I 2025-02-10 23:45:58,532] Trial 5 finished with value: 0.70568348123726 and parameters: {'C': 0.1000767483406732, 'penalty': 'l1'}. Best is trial 0 with value: 0.878925174303404.\n",
      "[I 2025-02-10 23:45:58,853] Trial 6 finished with value: 0.7090250664964544 and parameters: {'C': 0.021343866513885153, 'penalty': 'l2'}. Best is trial 0 with value: 0.878925174303404.\n",
      "[I 2025-02-10 23:45:59,125] Trial 7 finished with value: 0.4301544554731719 and parameters: {'C': 0.0012103683689865543, 'penalty': 'l1'}. Best is trial 0 with value: 0.878925174303404.\n",
      "[I 2025-02-10 23:45:59,592] Trial 8 finished with value: 0.8505913163231466 and parameters: {'C': 0.7691975156741875, 'penalty': 'l1'}. Best is trial 0 with value: 0.878925174303404.\n",
      "[I 2025-02-10 23:46:00,169] Trial 9 finished with value: 0.8785160136483773 and parameters: {'C': 2.0536075479809486, 'penalty': 'l1'}. Best is trial 0 with value: 0.878925174303404.\n",
      "[I 2025-02-10 23:46:00,393] Trial 10 finished with value: 0.678338738213974 and parameters: {'C': 0.00010700788504078393, 'penalty': 'l2'}. Best is trial 0 with value: 0.878925174303404.\n",
      "[I 2025-02-10 23:46:01,452] Trial 11 finished with value: 0.8660370845443085 and parameters: {'C': 7.583989786728681, 'penalty': 'l1'}. Best is trial 0 with value: 0.878925174303404.\n",
      "[I 2025-02-10 23:46:02,007] Trial 12 finished with value: 0.8657981478364928 and parameters: {'C': 1.1388444605517898, 'penalty': 'l1'}. Best is trial 0 with value: 0.878925174303404.\n",
      "[I 2025-02-10 23:46:03,098] Trial 13 finished with value: 0.8670258681453282 and parameters: {'C': 7.400488898706885, 'penalty': 'l1'}. Best is trial 0 with value: 0.878925174303404.\n",
      "[I 2025-02-10 23:46:03,480] Trial 14 finished with value: 0.7316986439693652 and parameters: {'C': 0.13367516711566912, 'penalty': 'l1'}. Best is trial 0 with value: 0.878925174303404.\n",
      "[I 2025-02-10 23:46:03,922] Trial 15 finished with value: 0.8392373755562202 and parameters: {'C': 0.612712667832825, 'penalty': 'l1'}. Best is trial 0 with value: 0.878925174303404.\n",
      "[I 2025-02-10 23:46:04,554] Trial 16 finished with value: 0.8797094182697464 and parameters: {'C': 2.6505117928214315, 'penalty': 'l1'}. Best is trial 16 with value: 0.8797094182697464.\n",
      "[I 2025-02-10 23:46:04,871] Trial 17 finished with value: 0.6248422266073598 and parameters: {'C': 0.03650365216874398, 'penalty': 'l1'}. Best is trial 16 with value: 0.8797094182697464.\n",
      "[I 2025-02-10 23:46:05,712] Trial 18 finished with value: 0.7991064318224955 and parameters: {'C': 0.3319773103909271, 'penalty': 'l2'}. Best is trial 16 with value: 0.8797094182697464.\n",
      "[I 2025-02-10 23:46:06,800] Trial 19 finished with value: 0.8628320353771892 and parameters: {'C': 9.048637775853432, 'penalty': 'l1'}. Best is trial 16 with value: 0.8797094182697464.\n",
      "[I 2025-02-10 23:46:07,599] Trial 20 finished with value: 0.8788570719353427 and parameters: {'C': 3.67039803163053, 'penalty': 'l1'}. Best is trial 16 with value: 0.8797094182697464.\n",
      "[I 2025-02-10 23:46:08,314] Trial 21 finished with value: 0.8797094357095332 and parameters: {'C': 3.0460529788597395, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:08,840] Trial 22 finished with value: 0.8750722719304594 and parameters: {'C': 1.5678243936074268, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:09,263] Trial 23 finished with value: 0.8263491055859928 and parameters: {'C': 0.4722626998962889, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:09,897] Trial 24 finished with value: 0.8797094182697464 and parameters: {'C': 2.6456944839067758, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:10,271] Trial 25 finished with value: 0.7488489595277772 and parameters: {'C': 0.1576997575254386, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:10,672] Trial 26 finished with value: 0.7351083548496705 and parameters: {'C': 0.05293229408127069, 'penalty': 'l2'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:11,466] Trial 27 finished with value: 0.877288624695494 and parameters: {'C': 4.1872383924409915, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:11,987] Trial 28 finished with value: 0.8612974736433952 and parameters: {'C': 0.9904884076404159, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:12,715] Trial 29 finished with value: 0.8788229538987951 and parameters: {'C': 3.4644534292371976, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:13,015] Trial 30 finished with value: 0.4434517640199174 and parameters: {'C': 0.01695581346336448, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:13,579] Trial 31 finished with value: 0.8760269549347186 and parameters: {'C': 1.666388162114971, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:14,506] Trial 32 finished with value: 0.8744245698694545 and parameters: {'C': 4.832245195134278, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:14,927] Trial 33 finished with value: 0.8057211162975099 and parameters: {'C': 0.3322556594869501, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:15,181] Trial 34 finished with value: 0.6863512855593623 and parameters: {'C': 0.003980896923334018, 'penalty': 'l2'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:15,765] Trial 35 finished with value: 0.8785501200583999 and parameters: {'C': 2.1738736544124424, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:16,165] Trial 36 finished with value: 0.7797741373191386 and parameters: {'C': 0.22772983618529716, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:16,716] Trial 37 finished with value: 0.7476215763881562 and parameters: {'C': 0.07764854997801929, 'penalty': 'l2'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:17,221] Trial 38 finished with value: 0.8515460051406677 and parameters: {'C': 0.7906607621620132, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:18,267] Trial 39 finished with value: 0.8621501106409152 and parameters: {'C': 9.420610125400447, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:18,456] Trial 40 finished with value: 0.6799411930383858 and parameters: {'C': 0.0003467165455401625, 'penalty': 'l2'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:19,025] Trial 41 finished with value: 0.8797094182697464 and parameters: {'C': 2.98711076310548, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:19,556] Trial 42 finished with value: 0.8795048263157085 and parameters: {'C': 2.37256208836678, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:20,129] Trial 43 finished with value: 0.8797094182697464 and parameters: {'C': 2.644797781958482, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:20,880] Trial 44 finished with value: 0.8719697222045403 and parameters: {'C': 5.660507152558895, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:21,310] Trial 45 finished with value: 0.8692759436450725 and parameters: {'C': 1.263230126865083, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:21,830] Trial 46 finished with value: 0.8794366425619746 and parameters: {'C': 2.6744189526610365, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:22,529] Trial 47 finished with value: 0.8735039816486936 and parameters: {'C': 5.169425993477837, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:22,903] Trial 48 finished with value: 0.8270651134792406 and parameters: {'C': 0.47800202211185927, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n",
      "[I 2025-02-10 23:46:23,370] Trial 49 finished with value: 0.8717649965454688 and parameters: {'C': 1.3954448909673005, 'penalty': 'l1'}. Best is trial 21 with value: 0.8797094357095332.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 3.0460529788597395, 'penalty': 'l1'}\n",
      "Test Accuracy: 0.8803\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Ensure df is defined (Replace with actual DataFrame loading)\n",
    "# df = pd.read_csv(\"your_dataset.csv\")  # Uncomment this line if needed\n",
    "\n",
    "# Step 1: Remove rows where the target labels (category) are NaN\n",
    "df = df.dropna(subset=['category'])\n",
    "\n",
    "# Step 2: TF-IDF vectorization setup\n",
    "ngram_range = (1, 3)  # Trigram\n",
    "max_features = 10000  # Set max_features to 10000\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "\n",
    "# **Step 3: Train-test split**\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category']\n",
    ")\n",
    "\n",
    "# **Step 4: Fit TF-IDF only on training data**\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# **Step 5: Compute Class Weights Correctly**\n",
    "all_classes = np.unique(np.concatenate([y_train, y_test]))  # Ensure all labels are considered\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=all_classes, y=y_train)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(all_classes, class_weights)}\n",
    "\n",
    "# Step 6: Optuna objective function with Stratified K-Fold CV\n",
    "def objective_logreg(trial):\n",
    "    C = trial.suggest_float('C', 1e-4, 10.0, log=True)\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "    solver = 'liblinear' if penalty == 'l1' else 'lbfgs'\n",
    "\n",
    "    model = LogisticRegression(\n",
    "        C=C, penalty=penalty, solver=solver, class_weight=class_weight_dict, random_state=42\n",
    "    )\n",
    "\n",
    "    # Perform Stratified K-Fold Cross-Validation\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X_train_vec, y_train, cv=skf, scoring='accuracy', n_jobs=-1)\n",
    "\n",
    "    return scores.mean()  # Return mean accuracy across folds\n",
    "\n",
    "# Step 7: Run Optuna Optimization\n",
    "def run_optuna_experiment():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective_logreg, n_trials=50)  # 50 trials\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = study.best_params\n",
    "    best_model = LogisticRegression(\n",
    "        C=best_params['C'], penalty=best_params['penalty'], \n",
    "        solver='liblinear' if best_params['penalty'] == 'l1' else 'lbfgs',\n",
    "        class_weight=class_weight_dict, random_state=42\n",
    "    )\n",
    "\n",
    "    # Train final model on full training data\n",
    "    best_model.fit(X_train_vec, y_train)\n",
    "\n",
    "    # Evaluate on test data\n",
    "    y_pred = best_model.predict(X_test_vec)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Run the experiment\n",
    "run_optuna_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8803\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.84      0.78      0.81      1650\n",
      "           0       0.86      0.96      0.91      2529\n",
      "           1       0.92      0.87      0.90      3154\n",
      "\n",
      "    accuracy                           0.88      7333\n",
      "   macro avg       0.87      0.87      0.87      7333\n",
      "weighted avg       0.88      0.88      0.88      7333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Ensure df is defined (Replace with actual DataFrame loading)\n",
    "# df = pd.read_csv(\"your_dataset.csv\")  # Uncomment if needed\n",
    "\n",
    "# Step 1: Remove rows where the target labels (category) are NaN\n",
    "df = df.dropna(subset=['category'])\n",
    "\n",
    "# Step 2: TF-IDF vectorization setup\n",
    "ngram_range = (1, 3)  # Trigram\n",
    "max_features = 10000  # Set max_features to 10000\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "\n",
    "# **Step 3: Train-test split**\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category']\n",
    ")\n",
    "\n",
    "# **Step 4: Fit TF-IDF only on training data**\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# **Step 5: Compute Class Weights Correctly**\n",
    "all_classes = np.unique(np.concatenate([y_train, y_test]))  # Ensure all labels are considered\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=all_classes, y=y_train)\n",
    "class_weight_dict = {cls: weight for cls, weight in zip(all_classes, class_weights)}\n",
    "\n",
    "# **Step 6: Train the Best Model**\n",
    "best_model = LogisticRegression(\n",
    "    C=3.04, penalty='l1', solver='liblinear', class_weight=class_weight_dict, random_state=42\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "best_model.fit(X_train_vec, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = best_model.predict(X_test_vec)\n",
    "\n",
    "# **Step 7: Evaluate the Model**\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36662, 2)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../reddit_preprocessing.csv').dropna()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-02-11 00:13:10,095] A new study created in memory with name: no-name-9e0ca7c6-b117-42b6-9856-9a7946591b7b\n",
      "[I 2025-02-11 00:13:11,167] Trial 0 finished with value: 0.8785842264684227 and parameters: {'C': 2.1613827154073753, 'penalty': 'l1'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "[I 2025-02-11 00:13:11,402] Trial 1 finished with value: 0.6807936381982491 and parameters: {'C': 0.00121267920942315, 'penalty': 'l2'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "[I 2025-02-11 00:13:11,843] Trial 2 finished with value: 0.6985917372033383 and parameters: {'C': 0.011992363614706344, 'penalty': 'l2'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "[I 2025-02-11 00:13:12,036] Trial 3 finished with value: 0.6779977554994188 and parameters: {'C': 0.00010415126926001264, 'penalty': 'l2'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "[I 2025-02-11 00:13:13,333] Trial 4 finished with value: 0.878481936304666 and parameters: {'C': 1.9786901345650996, 'penalty': 'l1'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "c:\\Users\\Aryan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Aryan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\Aryan\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[I 2025-02-11 00:13:19,060] Trial 5 finished with value: 0.8419652140196122 and parameters: {'C': 3.738583045790526, 'penalty': 'l2'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "[I 2025-02-11 00:13:23,549] Trial 6 finished with value: 0.8221894141074507 and parameters: {'C': 0.7788403627493072, 'penalty': 'l2'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "[I 2025-02-11 00:13:23,747] Trial 7 finished with value: 0.6796002858962409 and parameters: {'C': 0.0008571643356920398, 'penalty': 'l2'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "[I 2025-02-11 00:13:23,984] Trial 8 finished with value: 0.4301544554731719 and parameters: {'C': 0.0011424080646221463, 'penalty': 'l1'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "[I 2025-02-11 00:13:24,311] Trial 9 finished with value: 0.6874764599208991 and parameters: {'C': 0.005021919378463228, 'penalty': 'l2'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "[I 2025-02-11 00:13:24,861] Trial 10 finished with value: 0.7468372684759284 and parameters: {'C': 0.15439204130400738, 'penalty': 'l1'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "[I 2025-02-11 00:13:27,064] Trial 11 finished with value: 0.8626615556464362 and parameters: {'C': 9.141029064678811, 'penalty': 'l1'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "[I 2025-02-11 00:13:27,621] Trial 12 finished with value: 0.7797059477521422 and parameters: {'C': 0.22744321360231795, 'penalty': 'l1'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "[I 2025-02-11 00:13:28,514] Trial 13 finished with value: 0.8672642758462729 and parameters: {'C': 1.1903956869077756, 'penalty': 'l1'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "[I 2025-02-11 00:13:29,084] Trial 14 finished with value: 0.758634604199675 and parameters: {'C': 0.17558192984299267, 'penalty': 'l1'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "[I 2025-02-11 00:13:29,869] Trial 15 finished with value: 0.8752086568777143 and parameters: {'C': 1.5789906812173822, 'penalty': 'l1'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "[I 2025-02-11 00:13:30,267] Trial 16 finished with value: 0.6538236820099006 and parameters: {'C': 0.056767595815077454, 'penalty': 'l1'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "[I 2025-02-11 00:13:31,973] Trial 17 finished with value: 0.8699580776587901 and parameters: {'C': 6.258161132440429, 'penalty': 'l1'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "[I 2025-02-11 00:13:32,689] Trial 18 finished with value: 0.8317362325235168 and parameters: {'C': 0.5214810334483975, 'penalty': 'l1'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "[I 2025-02-11 00:13:33,041] Trial 19 finished with value: 0.6053735529700102 and parameters: {'C': 0.03185584868217329, 'penalty': 'l1'}. Best is trial 0 with value: 0.8785842264684227.\n",
      "[I 2025-02-11 00:13:34,184] Trial 20 finished with value: 0.8798457741506895 and parameters: {'C': 2.8708144097830135, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:13:35,446] Trial 21 finished with value: 0.8793002866810312 and parameters: {'C': 3.1567480060122253, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:13:36,712] Trial 22 finished with value: 0.8783456094900345 and parameters: {'C': 3.89958255320494, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:13:37,439] Trial 23 finished with value: 0.8207574041342177 and parameters: {'C': 0.4274735652026292, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:13:38,767] Trial 24 finished with value: 0.8780045802693808 and parameters: {'C': 1.9402798697632118, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:13:42,214] Trial 25 finished with value: 0.8610249420926406 and parameters: {'C': 9.985721761703841, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:13:42,773] Trial 26 finished with value: 0.6777930530933969 and parameters: {'C': 0.07451372330113902, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:13:43,541] Trial 27 finished with value: 0.8161885636271734 and parameters: {'C': 0.394223302375788, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:13:45,301] Trial 28 finished with value: 0.8791980255835862 and parameters: {'C': 3.3027772697343565, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:13:47,159] Trial 29 finished with value: 0.8777318685074944 and parameters: {'C': 4.021225204252917, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:13:48,128] Trial 30 finished with value: 0.8628999807871681 and parameters: {'C': 1.0422070736794014, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:13:49,539] Trial 31 finished with value: 0.8794707373454728 and parameters: {'C': 2.6752984236193154, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:13:51,474] Trial 32 finished with value: 0.879198019770324 and parameters: {'C': 3.4267690700353586, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:13:52,561] Trial 33 finished with value: 0.860820135047897 and parameters: {'C': 0.9803308918887961, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:13:54,293] Trial 34 finished with value: 0.8789933638704003 and parameters: {'C': 2.288223032784047, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:13:56,793] Trial 35 finished with value: 0.8721060897120081 and parameters: {'C': 5.606293288667117, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:13:57,359] Trial 36 finished with value: 0.6896927080472117 and parameters: {'C': 0.005895862287719867, 'penalty': 'l2'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:13:57,574] Trial 37 finished with value: 0.22496504921362548 and parameters: {'C': 0.00014359378403770658, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:14:01,372] Trial 38 finished with value: 0.8187457479619429 and parameters: {'C': 0.6515210910376581, 'penalty': 'l2'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:14:03,186] Trial 39 finished with value: 0.8789933638704003 and parameters: {'C': 2.2796790045750654, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:14:05,766] Trial 40 finished with value: 0.795355842866357 and parameters: {'C': 0.28840465535726345, 'penalty': 'l2'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:14:07,459] Trial 41 finished with value: 0.8787888939948709 and parameters: {'C': 3.5879906620046533, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:14:08,400] Trial 42 finished with value: 0.8790274644671607 and parameters: {'C': 2.3181528664966633, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:14:10,011] Trial 43 finished with value: 0.8707422634925092 and parameters: {'C': 5.941763781097302, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:14:11,138] Trial 44 finished with value: 0.8787547992113728 and parameters: {'C': 3.5964881156817405, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:14:11,959] Trial 45 finished with value: 0.8710830485561456 and parameters: {'C': 1.3484801161702074, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:14:14,501] Trial 46 finished with value: 0.8227008591129717 and parameters: {'C': 0.7882083225107187, 'penalty': 'l2'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:14:14,936] Trial 47 finished with value: 0.7247771820152777 and parameters: {'C': 0.1249951906493446, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:14:16,702] Trial 48 finished with value: 0.8681851256638382 and parameters: {'C': 6.8888135253623055, 'penalty': 'l1'}. Best is trial 20 with value: 0.8798457741506895.\n",
      "[I 2025-02-11 00:14:17,719] Trial 49 finished with value: 0.879845779963952 and parameters: {'C': 2.873718841872781, 'penalty': 'l1'}. Best is trial 49 with value: 0.879845779963952.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 2.873718841872781, 'penalty': 'l1'}\n",
      "Test Accuracy: 0.8800\n"
     ]
    }
   ],
   "source": [
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Step 1: Remove rows where the target labels (category) are NaN\n",
    "df = df.dropna(subset=['category'])\n",
    "\n",
    "# Step 2: TF-IDF vectorization setup\n",
    "ngram_range = (1, 3)  # Trigram\n",
    "max_features = 10000  # Set max_features to 1000\n",
    "vectorizer = TfidfVectorizer(ngram_range=ngram_range, max_features=max_features)\n",
    "\n",
    "# **Step 3: Train-test split**\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df['clean_comment'], df['category'], test_size=0.2, random_state=42, stratify=df['category']\n",
    ")\n",
    "\n",
    "# **Step 4: Fit TF-IDF only on training data**\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# Step 5: Optuna objective function with Stratified K-Fold CV\n",
    "def objective_logreg(trial):\n",
    "    C = trial.suggest_float('C', 1e-4, 10.0, log=True)\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "    solver = 'liblinear' if penalty == 'l1' else 'lbfgs'\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = []\n",
    "\n",
    "    # Perform cross-validation manually\n",
    "    for train_idx, val_idx in skf.split(X_train_vec, y_train):\n",
    "        X_fold_train, X_fold_val = X_train_vec[train_idx], X_train_vec[val_idx]\n",
    "        y_fold_train, y_fold_val = y_train.iloc[train_idx], y_train.iloc[val_idx]\n",
    "\n",
    "        # âœ… Compute Class Weights ONLY on the training fold (Fix Data Leakage)\n",
    "        fold_classes = np.unique(y_fold_train)\n",
    "        fold_class_weights = compute_class_weight(class_weight=\"balanced\", classes=fold_classes, y=y_fold_train)\n",
    "        fold_class_weight_dict = {cls: fold_class_weights[i] for i, cls in enumerate(fold_classes)}\n",
    "\n",
    "        # Train Logistic Regression model on this fold\n",
    "        model = LogisticRegression(\n",
    "            C=C, penalty=penalty, solver=solver, class_weight=fold_class_weight_dict, random_state=42\n",
    "        )\n",
    "        model.fit(X_fold_train, y_fold_train)\n",
    "\n",
    "        # Evaluate on validation fold\n",
    "        y_val_pred = model.predict(X_fold_val)\n",
    "        fold_accuracy = accuracy_score(y_fold_val, y_val_pred)\n",
    "        scores.append(fold_accuracy)\n",
    "\n",
    "    return np.mean(scores)  # Return mean accuracy across folds\n",
    "\n",
    "# Step 6: Run Optuna with early stopping\n",
    "def run_optuna_experiment():\n",
    "    study = optuna.create_study(direction=\"maximize\")\n",
    "    study.optimize(objective_logreg, n_trials=50)  # 50 trials\n",
    "\n",
    "    # Get the best parameters\n",
    "    best_params = study.best_params\n",
    "    best_model = LogisticRegression(\n",
    "        C=best_params['C'], penalty=best_params['penalty'], \n",
    "        solver='liblinear' if best_params['penalty'] == 'l1' else 'lbfgs',\n",
    "        class_weight=\"balanced\",  # Now safe to compute globally on `y_train`\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    # Train final model on full training data\n",
    "    best_model.fit(X_train_vec, y_train)\n",
    "\n",
    "    # Evaluate on test data\n",
    "    y_pred = best_model.predict(X_test_vec)\n",
    "    test_accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"Best Parameters: {best_params}\")\n",
    "    print(f\"Test Accuracy: {test_accuracy:.4f}\")\n",
    "\n",
    "# Run the experiment\n",
    "run_optuna_experiment()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
